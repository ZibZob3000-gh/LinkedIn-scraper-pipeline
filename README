# ğŸ§  Skill Extractor ETL Pipeline

This repository contains the **Skill Extractor ETL pipeline**, which processes LinkedIn data to identify and extract professional skills using a local AI model.

The pipeline can be set up in **two ways**:

1. ğŸ³ **Docker Setup** â€“ Easiest way to run the pipeline (recommended for production).
2. ğŸ’» **Local Setup (via GitHub)** â€“ For direct code access and development environments.

---

## âš™ï¸ Requirements

- **Ollama** (for the local AI model)
  ğŸ‘‰ [https://ollama.com/download](https://ollama.com/download)
- **Llama 3 model**
  After installing Ollama, download the model:
  ```bash
  ollama pull llama3:8b-instruct-q4_K_M
  ```

---

## ğŸš€ Setup Options

### Option 1: Docker Setup (Recommended)
If you prefer a fully self-contained environment, follow:
ğŸ‘‰ [README_DOCKER.md](./README_DOCKER.md)

This option runs everything inside a container â€” no need to install Python or dependencies manually.

---

### Option 2: Local (GitHub) Setup
If you want to run the code directly from this repository, follow:
ğŸ‘‰ [README_LOCAL.md](./README_LOCAL.md)

Make sure Ollama and the required model are installed locally before running the scripts.

---

## ğŸ§© Quick Summary

| Setup Type | When to Use | Requirements |
|-------------|--------------|---------------|
| **Docker** | You want the standard setup and an isolated environment | Only Docker + Ollama |
| **Local (GitHub)** | You want to view or modify the Python code | Python + Ollama |

---

## ğŸ“ Support

If you encounter any issues, please make sure the Ollama server is running before executing the pipeline:
```bash
ollama serve &
```

For further assistance, contact: **Thibaud Vandendooren**
