# ğŸ§  Skill Extractor ETL Pipeline

This repository contains the **Skill Extractor ETL Pipeline**, which processes LinkedIn job data to extract and enrich professional skills using the **Mistral hosted AI API** (no local model required).

You can run the pipeline in **two ways**:
1. ğŸ³ **Docker Setup** â€“ Recommended for production or easy deployment.
2. ğŸ’» **Local Setup** â€“ For direct code access, debugging, or customization.

---

## âš™ï¸ Overview

The ETL pipeline performs:
- **Extraction** of job postings from a PostgreSQL database.
- **Transformation** using an AI model (via Mistral API).
- **Loading** of enriched job records back into the database.

---

## ğŸªœ Setup Options

### ğŸ³ Option 1: Docker Setup (Recommended)

Run everything inside a lightweight container â€” no need to install Python or dependencies manually.

#### 1ï¸âƒ£ Prerequisites
- [Install Docker](https://www.docker.com/get-started)
- Ensure Docker is running on your machine

#### 2ï¸âƒ£ Build the image
If youâ€™re building locally:
```bash
docker build -t skill-extractor:latest .
```

Or, if you already have a `.tar` image archive:
```bash
docker load -i skill-extractor.tar
```

#### 3ï¸âƒ£ Run the container
```bash
docker run -it --env-file .env -v /path/to/local/project:/app skill-extractor:latest
```
Replace `/path/to/local/project` with your actual project folder path.

ğŸ’¡ **Tip:** The `.env` file should contain your Mistral API key, e.g.:
```
MISTRAL_API_KEY=sk-xxxxxx
```

---

### ğŸ’» Option 2: Local Setup (Development Mode)

Run the code directly from your local environment â€” ideal for modifying logic or testing.

#### 1ï¸âƒ£ Prerequisites
- **Python 3.10+**
- **pip** (comes with Python)
- **PostgreSQL** (for data storage)
- **Mistral API Key** (get one at [https://mistral.ai](https://mistral.ai))

#### 2ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

#### 3ï¸âƒ£ Configure environment
Create a `.env` file in the project root:
```
MISTRAL_API_KEY=sk-your-key
DB_HOST=localhost
DB_NAME=your_database
DB_USER=your_user
DB_PASSWORD=your_password
```

#### 4ï¸âƒ£ Run the pipeline
```bash
python main.py
```

---

## âš¡ Model Configuration

The pipeline uses Mistralâ€™s hosted model by default:

```yaml
llm:
  model_name: "mistral-small-latest"
  api_key: "your_api_key_here"
  max_retries: 3
  backoff_strategy: "exponential"
  temperature: 0.2
```

You can edit these settings inside your `config.yaml` file.

---

## ğŸ§© Summary of Options

| Setup Type | When to Use | Requirements |
|-------------|--------------|---------------|
| **Docker** | Fastest setup; no Python dependencies | Docker |
| **Local (GitHub)** | For debugging or development | Python + `.env` file with API key |

---

## ğŸ“Š Notes

- The ETL pipeline automatically retries failed API calls using exponential backoff.
- The hosted **Mistral API** handles all inference â€” no local model download is required.
- Ensure your PostgreSQL instance is reachable from the environment youâ€™re running in.
- You can monitor API usage in your [La Plateforme dashboard](https://console.mistral.ai).

---

## ğŸ§° Useful Commands

Rebuild and export Docker image:
```bash
docker build -t skill-extractor:latest .
docker save -o skill-extractor.tar skill-extractor:latest
```

Run locally for testing:
```bash
python main.py --mode test
```

---

## ğŸ§ª Quick-Start: Test Your Mistral API Key

Before running the full ETL, you can verify that your Mistral API key works by running this simple Python test:

```python
import os
from openai import OpenAI

client = OpenAI(api_key=os.getenv("MISTRAL_API_KEY"), base_url="https://api.mistral.ai/v1")

response = client.chat.completions.create(
    model="mistral-small-latest",
    messages=[{"role": "user", "content": "Hello! Can you confirm my API key works?"}]
)

print(response.choices[0].message.content)
```

âœ… If you see a friendly reply, your key and API setup are working correctly.

---

## ğŸ“ Support

For questions or issues, contact:
**Thibaud Vandendooren**
