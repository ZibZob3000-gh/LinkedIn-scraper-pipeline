# 🧠 Skill Extractor ETL Pipeline

This repository contains the **Skill Extractor ETL pipeline**, which processes LinkedIn data to identify and extract professional skills using a local AI model.

The pipeline can be set up in **two ways**:

1. 🐳 **Docker Setup** – Easiest way to run the pipeline (recommended for production).
2. 💻 **Local Setup (via GitHub)** – For direct code access and development environments.

---

## ⚙️ Requirements

- **Ollama** (for the local AI model)
  👉 [https://ollama.com/download](https://ollama.com/download)
- **Llama 3 model**
  After installing Ollama, download the model:
  ```bash
  ollama pull llama3:8b-instruct-q4_K_M
  ```

---

## 🚀 Setup Options

### Option 1: Docker Setup (Recommended)
If you prefer a fully self-contained environment, follow:
👉 [README_DOCKER.md](./README_DOCKER.md)

This option runs everything inside a container — no need to install Python or dependencies manually.

---

### Option 2: Local (GitHub) Setup
If you want to run the code directly from this repository, follow:
👉 [README_LOCAL.md](./README_LOCAL.md)

Make sure Ollama and the required model are installed locally before running the scripts.

---

## 🧩 Quick Summary

| Setup Type | When to Use | Requirements |
|-------------|--------------|---------------|
| **Docker** | You want the standard setup and an isolated environment | Only Docker + Ollama |
| **Local (GitHub)** | You want to view or modify the Python code | Python + Ollama |

---

## 📞 Support

If you encounter any issues, please make sure the Ollama server is running before executing the pipeline:
```bash
ollama serve &
```

For further assistance, contact: **Thibaud Vandendooren**
